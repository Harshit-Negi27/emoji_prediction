{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5941ea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "499dee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "train_df = pd.read_csv('Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8f1fe07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Shape:        Unnamed: 0                                               TEXT  Label\n",
      "0               0  Vacation wasted ! #vacation2017 #photobomb #ti...      0\n",
      "1               1  Oh Wynwood, you‚Äôre so funny! : @user #Wynwood ...      1\n",
      "2               2  Been friends since 7th grade. Look at us now w...      2\n",
      "3               3  This is what it looks like when someone loves ...      3\n",
      "4               4  RT @user this white family was invited to a Bl...      3\n",
      "...           ...                                                ...    ...\n",
      "69995       69995  Yes, I call Galina \"my Bubie\" Go follow my bea...      3\n",
      "69996       69996    I SEA you, Seattle @ Ballard Seafood Festival\\n     16\n",
      "69997       69997  If one of my daughters is wearing this and ask...      2\n",
      "69998       69998  Guess who whoop people on THEIR homecoming?! #...      3\n",
      "69999       69999  We Love you Robbie @ Heritage Memorial Cemeter...     14\n",
      "\n",
      "[70000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Shape of training data\n",
    "print(f\" Shape: {train_df}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dc20f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                               TEXT  Label\n",
      "0           0  Vacation wasted ! #vacation2017 #photobomb #ti...      0\n",
      "1           1  Oh Wynwood, you‚Äôre so funny! : @user #Wynwood ...      1\n",
      "2           2  Been friends since 7th grade. Look at us now w...      2\n",
      "3           3  This is what it looks like when someone loves ...      3\n",
      "4           4  RT @user this white family was invited to a Bl...      3\n"
     ]
    }
   ],
   "source": [
    "# First 5 rows\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "425b9bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 emoticons  number\n",
      "0           0         üòú       0\n",
      "1           1         üì∏       1\n",
      "2           2         üòç       2\n",
      "3           3         üòÇ       3\n",
      "4           4         üòâ       4\n"
     ]
    }
   ],
   "source": [
    "# Load the mapping data\n",
    "mapping_df = pd.read_csv('Mapping.csv')\n",
    "print(mapping_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9a0c596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to align for merging\n",
    "mapping_df = mapping_df.rename(columns={'number': 'Label', 'emoticons': 'emoji'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe66c714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                               TEXT  Label emoji\n",
      "0           0  Vacation wasted ! #vacation2017 #photobomb #ti...      0     üòú\n",
      "1           1  Oh Wynwood, you‚Äôre so funny! : @user #Wynwood ...      1     üì∏\n",
      "2           2  Been friends since 7th grade. Look at us now w...      2     üòç\n",
      "3           3  This is what it looks like when someone loves ...      3     üòÇ\n",
      "4           4  RT @user this white family was invited to a Bl...      3     üòÇ\n"
     ]
    }
   ],
   "source": [
    "# Merge label ‚Üí emoji mapping into train_df\n",
    "train_df = train_df.merge(mapping_df[['Label', 'emoji']], on='Label')\n",
    "\n",
    "# Preview of the new dataframe\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9040b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vacation wasted ! #vacation2017 #photobomb #ti...</td>\n",
       "      <td>vacation wasted vacation photobomb tired vacat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oh Wynwood, you‚Äôre so funny! : @user #Wynwood ...</td>\n",
       "      <td>oh wynwood youre so funny wynwood art itwasam ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Been friends since 7th grade. Look at us now w...</td>\n",
       "      <td>been friends since th grade look at us now we ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is what it looks like when someone loves ...</td>\n",
       "      <td>this is what it looks like when someone loves ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @user this white family was invited to a Bl...</td>\n",
       "      <td>rt this white family was invited to a black ba...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                TEXT  \\\n",
       "0  Vacation wasted ! #vacation2017 #photobomb #ti...   \n",
       "1  Oh Wynwood, you‚Äôre so funny! : @user #Wynwood ...   \n",
       "2  Been friends since 7th grade. Look at us now w...   \n",
       "3  This is what it looks like when someone loves ...   \n",
       "4  RT @user this white family was invited to a Bl...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  vacation wasted vacation photobomb tired vacat...  \n",
       "1  oh wynwood youre so funny wynwood art itwasam ...  \n",
       "2  been friends since th grade look at us now we ...  \n",
       "3  this is what it looks like when someone loves ...  \n",
       "4  rt this white family was invited to a black ba...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Define a cleaning function\n",
    "def clean_text(text):\n",
    "    text = text.lower()                                # Lowercase\n",
    "    text = re.sub(r'@[\\w_]+', '', text)                # Remove @mentions\n",
    "    text = re.sub(r'#(\\w+)', r'\\1', text)              # Remove # but keep the word\n",
    "    text = re.sub(r'http\\S+', '', text)                # Remove links\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)                # Remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)                    # Remove numbers\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()           # Remove extra whitespace\n",
    "    return text\n",
    "\n",
    "# Apply cleaning\n",
    "train_df['clean_text'] = train_df['TEXT'].apply(clean_text)\n",
    "\n",
    "# Preview\n",
    "train_df[['TEXT', 'clean_text']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f159e5",
   "metadata": {},
   "source": [
    "### We ran a code which cleaned each tweet in the TEXT column by removing mentions, hashtags, links, punctuation, numbers, and extra spaces, and saves the result in a new column called clean_text. ‚úÖ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d6a458d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>Label</th>\n",
       "      <th>emoji</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Vacation wasted ! #vacation2017 #photobomb #ti...</td>\n",
       "      <td>0</td>\n",
       "      <td>üòú</td>\n",
       "      <td>vacation wasted vacation photobomb tired vacat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Oh Wynwood, you‚Äôre so funny! : @user #Wynwood ...</td>\n",
       "      <td>1</td>\n",
       "      <td>üì∏</td>\n",
       "      <td>oh wynwood youre so funny wynwood art itwasam ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Been friends since 7th grade. Look at us now w...</td>\n",
       "      <td>2</td>\n",
       "      <td>üòç</td>\n",
       "      <td>been friends since th grade look at us now we ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>This is what it looks like when someone loves ...</td>\n",
       "      <td>3</td>\n",
       "      <td>üòÇ</td>\n",
       "      <td>this is what it looks like when someone loves ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>RT @user this white family was invited to a Bl...</td>\n",
       "      <td>3</td>\n",
       "      <td>üòÇ</td>\n",
       "      <td>rt this white family was invited to a black ba...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               TEXT  Label emoji  \\\n",
       "0           0  Vacation wasted ! #vacation2017 #photobomb #ti...      0     üòú   \n",
       "1           1  Oh Wynwood, you‚Äôre so funny! : @user #Wynwood ...      1     üì∏   \n",
       "2           2  Been friends since 7th grade. Look at us now w...      2     üòç   \n",
       "3           3  This is what it looks like when someone loves ...      3     üòÇ   \n",
       "4           4  RT @user this white family was invited to a Bl...      3     üòÇ   \n",
       "\n",
       "                                          clean_text  \n",
       "0  vacation wasted vacation photobomb tired vacat...  \n",
       "1  oh wynwood youre so funny wynwood art itwasam ...  \n",
       "2  been friends since th grade look at us now we ...  \n",
       "3  this is what it looks like when someone loves ...  \n",
       "4  rt this white family was invited to a black ba...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean dataframe \n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6e3e31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(columns=['TEXT'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bb6fc66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Label</th>\n",
       "      <th>emoji</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>üòú</td>\n",
       "      <td>vacation wasted vacation photobomb tired vacat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>üì∏</td>\n",
       "      <td>oh wynwood youre so funny wynwood art itwasam ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>üòç</td>\n",
       "      <td>been friends since th grade look at us now we ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>üòÇ</td>\n",
       "      <td>this is what it looks like when someone loves ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>üòÇ</td>\n",
       "      <td>rt this white family was invited to a black ba...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Label emoji                                         clean_text\n",
       "0           0      0     üòú  vacation wasted vacation photobomb tired vacat...\n",
       "1           1      1     üì∏  oh wynwood youre so funny wynwood art itwasam ...\n",
       "2           2      2     üòç  been friends since th grade look at us now we ...\n",
       "3           3      3     üòÇ  this is what it looks like when someone loves ...\n",
       "4           4      3     üòÇ  rt this white family was invited to a black ba..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdb57bc",
   "metadata": {},
   "source": [
    "### Now we'll convert text to numbers. We'll->\n",
    "##### 1)Convert the cleaned text into numeric sequences using Tokenizer\n",
    "\n",
    "##### 2)Pad those sequences so they‚Äôre all the same length\n",
    "\n",
    "##### 3)Convert the emoji Label column into categorical one-hot labels for training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f7e6606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Set a vocabulary size\n",
    "vocab_size = 5000\n",
    "oov_token = \"<OOV\"\n",
    "\n",
    "# Create and fit tokenize\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token = oov_token)\n",
    "tokenizer.fit_on_texts(train_df['clean_text'])\n",
    "\n",
    "# Converting text to sequences \n",
    "sequences = tokenizer.texts_to_sequences(train_df['clean_text'])\n",
    "\n",
    "# Pad the sequences to same length \n",
    "max_length = max(len(seq) for seq in sequences)\n",
    "padded_sequence = pad_sequences(sequences, maxlen = max_length, padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83caf7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes : 20\n"
     ]
    }
   ],
   "source": [
    "# One-Hot Encode the Labels\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Check how many unique labels you have \n",
    "num_classes = train_df['Label'].nunique()\n",
    "print(f\"Number of classes : {num_classes}\")\n",
    "\n",
    "one_hot_labels = to_categorical(train_df['Label'], num_classes=num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae71a75b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>emoji</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>üòú</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>üì∏</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>üòç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>üòÇ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>üòâ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>üéÑ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>üì∑</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>üî•</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>üòò</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>‚ù§</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>üòÅ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11</td>\n",
       "      <td>üá∫üá∏</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12</td>\n",
       "      <td>‚òÄ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13</td>\n",
       "      <td>‚ú®</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>14</td>\n",
       "      <td>üíô</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>15</td>\n",
       "      <td>üíï</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>16</td>\n",
       "      <td>üòé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>17</td>\n",
       "      <td>üòä</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>18</td>\n",
       "      <td>üíú</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>19</td>\n",
       "      <td>üíØ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Label emoji\n",
       "0       0     üòú\n",
       "1       1     üì∏\n",
       "2       2     üòç\n",
       "3       3     üòÇ\n",
       "5       4     üòâ\n",
       "6       5     üéÑ\n",
       "7       6     üì∑\n",
       "9       7     üî•\n",
       "10      8     üòò\n",
       "11      9     ‚ù§\n",
       "12     10     üòÅ\n",
       "13     11    üá∫üá∏\n",
       "14     12     ‚òÄ\n",
       "16     13     ‚ú®\n",
       "25     14     üíô\n",
       "32     15     üíï\n",
       "42     16     üòé\n",
       "44     17     üòä\n",
       "58     18     üíú\n",
       "89     19     üíØ"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will show you all 20 emoji‚Äìlabel pairs being used in the dataset\n",
    "train_df[['Label', 'emoji']].drop_duplicates().sort_values('Label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05c891a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
